{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Iguazio Data Science Platform\n",
    "\n",
    "An initial introduction to the Iguazio Data Science Platform and the platform tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Platform Overview](#platform-overview)\n",
    "- [Data Science Workflow](#data-science-workflow)\n",
    "- [The Tutorial Notebooks](#the-tutorial-notebooks)\n",
    "- [End-to-End Use-Case Applications](#end-to-end-use-case-applications)\n",
<<<<<<< HEAD
    "  \n",
    "  Pre-deployed demos &mdash;\n",
    "  - [Natural language processing (NLP)](demos/nlp/nlp-example.ipynb)\n",
    "  - [Stream enrichment](demos/stream-enrich/stream-enrich.ipynb)\n",
    "  - [Smart stock trading](demos/stocks/01-gen-demo-data.ipynb)\n",
    "  - [Location-based recommendations](demos/location-based-recommendations/01-generate-stores-and-customers.ipynb)\n",
    "  - [Real-time-user-segmentation](demos/slots-stream/real-time-user-segmentation.ipynb)\n",
    "  \n",
    "  Additional demos (see the [download instructions](#mlrun-demos-download)) &mdash;\n",
    "  - [XGBoost classification](demos/xgboost/train_xgboost_serverless.ipynb)\n",
    "  - [LightGBM classification](demos/lightgbm/README.md)\n",
    "  - [Face recognition](demos/faces/README.md)\n",
    "  - [Serverless Spark](demos/spark/mlrun_sparkk8s.ipynb)\n",
    "  - [Image classification](demos/image_classification/README.md)\n",
    "  - [Predictive infrastructure monitoring](demos/netops/README.md)\n",
    "- [Jupyter Notebook Basics](#jupyter-notebook-basics)\n",
    "  - [Creating Virtual Environments in Jupyter Notebook](#creating-virtual-environments-in-jupyter-notebook)\n",
    "  - [Updating the Tutorial Notebooks](#update-notebooks)\n",
    "- [Additional Resources](#additional-resources)\n",
    "  - [Platform Documentation, Examples, and Sample Data Sets](#platform-resources)\n",
    "  - [Third-Party Documentation, Examples, and Sample Data Sets](#third-party-resources)\n",
    "- [Support](#support)"
=======
    "- [Additional Platform Resources](#platform-resources)\n",
    "- [Miscellaneous](#misc)"
>>>>>>> c2f6a71fe129ef2e0905d788e9045b1c40b6e2fe
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platform-overview\"></a>\n",
    "## Platform Overview\n",
    "\n",
    "The Iguazio Data Science Platform (**\"the platform\"**) is a fully integrated and secure data science platform as a service (PaaS), which simplifies development, accelerates performance, facilitates collaboration, and addresses operational challenges.\n",
    "The platform incorporates the following components:\n",
    "\n",
    "- A data science workbench that includes Jupyter Notebook, integrated analytics engines, and Python packages\n",
    "- Model management with experiments tracking and automated pipeline capabilities\n",
    "- Managed data and machine-learning (ML) services over a scalable Kubernetes cluster\n",
    "- A real-time serverless functions framework &mdash; Nuclio\n",
    "- An extremely fast and secure data layer that supports SQL, NoSQL, time-series databases, files (simple objects), and streaming\n",
    "- Integration with third-party data sources such as Amazon S3, HDFS, SQL databases, and streaming or messaging protocols\n",
    "- Real-time dashboards based on Grafana\n",
    "\n",
<<<<<<< HEAD
    "<br><img src=\"assets/images/igz-self-service-platform.png\" alt=\"Self-service data science platform\" width=\"650\"/><br>\n",
    "\n",
    "The platform uses [Kubernetes](https://kubernetes.io) (k8s) as the baseline cluster manager, and deploys various application microservices on top of Kubernetes to address different data science tasks.\n",
    "Most of the provided services support scaling out and GPU acceleration and have a secure and low-latency access to the platform's shared data store and file system, enabling high performance and scalability with maximum resource efficiency.\n",
    "\n",
    "The platform makes extensive use of [Nuclio serverless functions](https://github.com/nuclio/nuclio) to automate various tasks &mdash; such as data collection, extract-transform-load (ETL) processes, model serving, and batch jobs.\n",
    "Nuclio functions describe the code and include all the required resource definitions and configuration for running the code.\n",
    "The functions auto scale and can be versioned.\n",
    "The platform supports various methods for generating Nuclio functions &mdash; using the graphical dashboard, Docker, Git, or Jupyter Notebook &mdash; as demonstrated in the platform tutorials.\n",
    "\n",
    "For a more in-depth introduction to the platform, see the following resources:\n",
    "\n",
    "- [Components, Services, and Development Ecosystem](https://www.iguazio.com/docs/intro/latest-release/ecosystem)\n",
    "- [Introduction video](https://www.youtube.com/watch?v=hR_Hv0_WcUw)\n",
    "- [Unique data-layer architecture](https://www.iguazio.com/docs/intro/latest-release/architecture/)\n",
    "- [Creating and deploying Nuclio functions with Python and Jupyter Notebook](https://github.com/nuclio/nuclio-jupyter/blob/master/README.md)\n",
    "\n",
    "A good place to start your development is with the platform [tutorial Jupyter notebooks](https://github.com/v3io/tutorials), which are available in the home directory of the platform's Jupyter Notebook service; see especially the [getting-started examples](getting-started/getting-started-basic.ipynb) and full [use-case demo applications](demos/README.ipynb).\n",
    "You can find a tutorials overview in the [Jupyter Notebook Basics](#jupyter-notebook-basics) section of this document."
=======
    "<br><img src=\"./assets/images/igz-self-service-platform.png\" alt=\"Self-service data science platform\" width=\"650\"/><br>"
>>>>>>> c2f6a71fe129ef2e0905d788e9045b1c40b6e2fe
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-science-workflow\"></a>\n",
    "## Data Science Workflow\n",
    "\n",
    "The platform provides a complete data science workflow in a single ready-to-use platform that includes all the required building blocks for creating data science applications from research to production:\n",
    "\n",
    "- Collect, explore, and label data from various real-time or offline sources\n",
    "- Run ML training and validation at scale over multiple CPUs and GPUs\n",
    "- Deploy models and applications into production with serverless functions\n",
    "- Log, monitor, and visualize all your data and services\n",
    "\n",
    "![Data Science Workflow](./assets/images/igz-data-science-workflow.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"the-tutorial-notebooks\"></a>\n",
    "## The Tutorial Notebooks\n",
    "\n",
    "The home directory of the platform's running-user directory (**/User/&lt;running user&gt;**) contains pre-deployed tutorial Jupyter notebooks with code samples and documentation to assist you in your development &mdash; including a **demos** directory with end-to-end use-case applications (see the next section) and a **getting-started** directory with examples for performing basic tasks.\n",
    "\n",
    "> **Note:**\n",
    "> - To view and run the tutorials from the platform, you first need to create a Jupyter Notebook service.\n",
    "> - The **welcome.ipynb** notebook and main **README.md** file provide the same introduction in different formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "<a id=\"data-exploration-and-processing\"></a>\n",
    "### Exploring and Processing Data\n",
    "\n",
    "The platform includes a wide range of integrated open-source data query and exploration tools, including the following:\n",
    "\n",
    "- [Apache Spark](https://spark.apache.org/) data-processing engine &mdash; including the Spark SQL and Datasets, MLlib, R, and GraphX libraries &mdash; with real-time access to the platform's NoSQL data store and file system.\n",
    "  See the platform's [Spark APIs reference](https://www.iguazio.com/docs/reference/latest-release/api-reference/spark-apis/) and the examples in the [**spark-sql-analytics**](getting-started/spark-sql-analytics.ipynb) tutorial.\n",
    "- [Presto](http://prestodb.github.io/) distributed SQL query engine, which can be used to run interactive SQL queries over platform NoSQL tables or other object (file) data sources.\n",
    "  See the platform's [Presto reference](https://www.iguazio.com/docs/reference/latest-release/presto/).\n",
    "- [pandas](https://pandas.pydata.org/) Python analysis library, including structured DataFrames.\n",
    "- [Dask](https://dask.org/) parallel-computing Python library, including scaled pandas DataFrames.\n",
    "- [V3IO Frames](https://github.com/v3io/frames) &mdash; Iguazio's open-source data-access library, which provides a unified high-performance API for accessing NoSQL, stream, and time-series data in the platform's data store and features native integration with pandas and [NVIDIA RAPIDS](https://rapids.ai/).\n",
    "  See, for example, the [**frames**](getting-started/frames.ipynb) tutorial.\n",
    "- Built-in support for ML packages such as [scikit-learn](https://scikit-learn.org), [Pyplot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.html), [NumPy](http://www.numpy.org/), [PyTorch](https://pytorch.org/), and [TensorFlow](https://www.tensorflow.org/).\n",
    "\n",
    "All these tools are integrated with the platform's Jupyter Notebook service, allowing users to access the same data from Jupyter through different interfaces with minimal configuration overhead.\n",
    "Users can easily install additional Python packages by using the [Conda](https://anaconda.org/anaconda/conda) binary package and environment manager and the [pip](https://pip.pypa.io) Python package installer, which are both available as part of the Jupyter Notebook service.\n",
    "This design, coupled with the platform's unified data model, enables users to store and access data using different formats &mdash; such as NoSQL (\"key/value\"), time series, stream data, and files (simple objects) &mdash; and leverage different tools and APIs for accessing and manipulating the data, all from a single development environment (namely, Jupyter Notebook).\n",
    "\n",
    "> **Note:** You can deploy and manage application services, such as Spark and Jupyter Notebook, from the **Services** page of the platform dashboard.\n",
    "\n",
    "For more information and examples of data exploration with the platform, see the [**getting-started-basic**](getting-started/getting-started-basic.ipynb#gs-data-exploration-and-processing) tutorial Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"building-and-training-models\"></a>\n",
    "### Building and Training Models\n",
    "\n",
    "You can develop and test data science models in the platform's Jupyter Notebook service or in your preferred external editor.\n",
    "When your model is ready, you can train it in Jupyter Notebook or by using scalable cluster resources such as Nuclio functions, Dask, Spark ML, or Kubernetes jobs.\n",
    "You can find model-training examples in the platform's tutorial Jupyter notebooks:\n",
    "\n",
    "- The [NetOps demo](demos/netops/03-training.ipynb) tutorial demonstrates predictive infrastructure-monitoring using scikit-learn.\n",
    "- The [image-classification demo](demos/image-classification/01-image-classification.ipynb) tutorial demonstrates image recognition using TensorFlow and Horovod with MLRun.\n",
    "\n",
    "If you're are a beginner, you might find the following ML guide useful &mdash; [Machine Learning Algorithms In Layman's Terms](https://towardsdatascience.com/machine-learning-algorithms-in-laymans-terms-part-1-d0368d769a7b).\n",
    "\n",
    "<a id=\"experiment-tracking\"></a>\n",
    "#### Experiment Tracking\n",
=======
    "<a id=\"end-to-end-use-case-applications\"></a>\n",
    "## End-to-End Use-Case Applications\n",
>>>>>>> c2f6a71fe129ef2e0905d788e9045b1c40b6e2fe
    "\n",
    "Iguazio provides full end-to-end use-case applications (demos) that demonstrate how to use the platform and related tools to address data science requirements for different industries and implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predeployed-demos\"></a>\n",
    "### Pre-Deployed Platform Demos\n",
    "\n",
    "The platform comes pre-deployed with the following end-to-end use-case demos, which are available in the **demos** tutorial-notebooks directory.\n",
    "For more details, see [**demos/README.md**](demos/README.md) (available also as a [notebook](demos/README.ipynb)):\n",
    "\n",
    "- <a id=\"nlp-demo\"></a>[**Natural language processing (NLP)**](demos/nlp/nlp-example.ipynb) &mdash; processes natural-language textual data and generates a Nuclio serverless function that translates any given text string to another (configurable) language.\n",
    "- <a id=\"stream-enrich-demo\"></a>[**Stream enrichment**](demos/stream-enrich/stream-enrich.ipynb) &mdash; implements a typical stream-based data-engineering pipeline, including real-time data enrichment using a NoSQL table.\n",
    "- <a id=\"stocks-demo\"></a>[**Smart stock trading**](demos/stocks/01-gen-demo-data.ipynb) &mdash; reads stock-exchange data from an internet service into a time-series database (TSDB) and performs real-time market-sentiment analysis on specific stocks; the data is saved to a platform NoSQL table for generating reports and analyzing and visualizing the data on a Grafana dashboard.\n",
    "- <a id=\"real-time-user-segmentation-demo\"></a>[**Real-time user segmentation**](demos/slots-stream/real-time-user-segmentation.ipynb) &mdash; builds a stream-event processor on a sliding time window for tagging and untagging users based on programmatic rules of user behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"additional-demos\"></a>\n",
    "### Additional Demos\n",
    "\n",
    "You can download additional demos from GitHub &mdash; for example:\n",
    "\n",
    "- <a id=\"xgboost-demo\"></a>[**XGBoost classification**](https://github.com/mlrun/demo-xgb-project) &mdash; uses XGBoost to perform binary classification on the popular Iris ML data set, and runs parallel model training with hyperparameters.\n",
    "- <a id=\"image-classification-demo\"></a>[**Image classification**](https://github.com/mlrun/demo-image-classification) &mdash; builds and trains an ML model that identifies (recognizes) and classifies (labels) images by using Keras, TensorFlow, and Horovod.\n",
    "\n",
    "For information on the available demos, see the [demo listing](https://github.com/mlrun/demos/blob/master/README.md).<br>\n",
    "\n",
    "You can download all the additional demos from the [demos repository](https://github.com/mlrun/demos) by executing the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get additional demos\n",
    "!/User/get-additional-demos.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "The downloaded demos include the following applications; for more details, see [**demos/README-MLRUN.md**](demos/README-MLRUN.md) (which is created as part of the download):\n",
    "\n",
    "- <a id=\"xgboost-demo\"></a>**XGBoost classification** ([**xgboost**](demos/xgboost/train_xgboost_serverless.ipynb)) &mdash; uses XGBoost to perform binary classification on the Iris data set (a popular machine-learning use case), and runs parallel model training with hyperparameters.\n",
    "- <a id=\"lightgbm-demo\"></a>**LightGBM classification** ([**lightgbm**](demos/lightgbm/README.md)) &mdash; uses LightGBM to perform binary classification on the HIGGS data set (a popluar machine-learning competition use case), and runs parallel model training with hyperparameters.\n",
    "- <a id=\"face-reco-demo\"></a>**Face recognition** ([**faces**](demos/faces/README.md)) &mdash; implements real-time capture of face images, image recognition, and location tracking of identities.\n",
    "- <a id=\"serverless-spark-demo\"></a>**Serverless Spark** ([**spark**](demos/spark/mlrun_sparkk8s.ipynb)) &mdash; demonstrates how to run the same Spark job locally and as a distributed MLRun job over Kubernetes.\n",
    "  The Spark function can be incorporated as a step in various data-preparation and machine-learning scenarios.\n",
    "- <a id=\"image-classification-demo\"></a>**Image classification** ([**image_classification**](demos/image_classification/README.md)) &mdash; builds and trains an ML model that identifies (recognizes) and classifies (labels) images by using Keras, TensorFlow, and Horovod.\n",
    "- <a id=\"netops-demo\"></a>**Predictive infrastructure monitoring** ([**netops**](demos/netops/README.md)) &mdash; builds, trains, and deploys a machine-learning model for analyzing and predicting failure in network devices as part of a network operations (NetOps) flow.\n",
    "  The goal is to identify anomalies for device metrics &mdash; such as CPU, memory consumption, or temperature &mdash; which can signify an upcoming issue or failure.\n",
    "\n",
    "The pre-deployed demos include the following use-cases applications; for more details, see [**demos/README.md**](demos/README.md) (available also as a [notebook](demos/README.ipynb):\n",
=======
    "<a id=\"platform-resources\"></a>\n",
    "## Additional Platform Resources\n",
>>>>>>> c2f6a71fe129ef2e0905d788e9045b1c40b6e2fe
    "\n",
    "- [Introduction video](https://www.youtube.com/watch?v=8OmAN4wd7To)\n",
    "- [In-depth platform overview](platform-overview.ipynb) with a break down of the steps for developing a full data science workflow from development to production\n",
    "- [Platform components, services, and development ecosystem introduction](https://www.iguazio.com/docs/intro/latest-release/ecosystem/)\n",
    "- [References](https://iguazio.com/docs/reference/latest-release/)\n",
    "- [nuclio-jupyter SDK](https://github.com/nuclio/nuclio-jupyter/blob/master/README.md) for creating and deploying Nuclio functions with Python and Jupyter Notebook\n",
    "- [Iguazio sample data-set](http://iguazio-sample-data.s3.amazonaws.com/) public Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "<a id=\"jupyter-notebook-basics\"></a>\n",
    "## Jupyter Notebook Basics\n",
    "\n",
    "The platform's Jupyter Notebook service displays the JupyterLab UI, which consists of a collapsible left sidebar, a main work area (on the right), and a top menu bar.\n",
    "For details, see the [JupyterLab documentation](https://jupyterlab.readthedocs.io/en/stable/user/interface.html#the-jupyterlab-interface).\n",
    "\n",
    "The main work area (on the right) contains tabs of documents and activities &mdash; for creating, viewing, editing, and running  interactive notebooks, shell terminals, or consoles, as well as viewing and editing other common file types.\n",
    "To create a new notebook or terminal, select the **New Launcher** option (`+` icon) from the top action toolbar in the left sidebar.\n",
    "\n",
    "The top menu bar exposes available top-level actions, such as exporting a notebook in a different format.\n",
    "\n",
    "The left-sidebar menu contains commonly used tabs, including a **File Browser** (directory icon) for browsing files.<br>\n",
    "The home directory of the platform's Jupyter Notebook service contains the following files and directories:\n",
    "\n",
    "- **v3io** directory, which displays the contents of the `v3io` platform cluster data mount for browsing the contents of the cluster's data containers.\n",
    "  You can also browse the contents of the data containers from the **Data** page of the platform dashboard.\n",
    "- The contents of the running-user home directory &mdash; **users/&lt;running user&gt;**.\n",
    "  This directory contains the platform's [tutorial Jupyter notebooks](https://github.com/v3io/tutorials):\n",
    "\n",
    "  - **welcome.ipynb** / [**README.md**](../README.md) &mdash; the current document, which provides a short introduction to the platform and how to use it to implement a full data science workflow.\n",
    "  - [**getting-started**]() &mdash; a directory containing getting-started tutorials that explain and demonstrate how to perform different platform operations using the platform APIs and integrated tools.\n",
    "  - [**demos**](demos/README.ipynb) &mdash; a directory containing [end-to-end application use-case demos](#end-to-end-use-case-applications).\n",
    "  - Scripts and related notebooks for [updating the tutorial notebooks](#update-notebooks) and [downloading additional demo applications](#mlrun-demos-download).\n",
    "\n",
    "For information about the predefined data containers and how to reference data in these containers, see [Platform Data Containers](getting-started/getting-started-basic.ipynb/#platform-data-containers) in the [**getting-started-basic**](getting-started/getting-started-basic.ipynb) tutorial notebook."
=======
    "<a id=\"misc\"></a>\n",
    "## Miscellaneous"
>>>>>>> c2f6a71fe129ef2e0905d788e9045b1c40b6e2fe
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"creating-virtual-environments-in-jupyter-notebook\"></a>\n",
    "### Creating Virtual Environments in Jupyter Notebook\n",
    "\n",
    "A virtual environment is a named, isolated, working copy of Python that maintains its own files, directories, and paths so that you can work with specific versions of libraries or Python itself without affecting other Python projects.\n",
    "Virtual environments make it easy to cleanly separate projects and avoid problems with different dependencies and version requirements across components.\n",
    "See the [virutal-env](getting-started/virutal-env.ipynb) tutorial notebook for step-by-step instructions for using conda to create your own Python virtual environments, which will appear as custom kernels in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"update-notebooks\"></a>\n",
    "### Updating the Tutorial Notebooks to the Latest Version\n",
    "\n",
    "You can use the provided **igz-tutorials-get.sh** script to update the tutorial notebooks to the latest stable version available on [GitHub](https://github.com/v3io/tutorials/).\n",
    "For details, see the [**update-tutorials.ipynb**](update-tutorials.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"v3io-dir\"></a>\n",
    "### The v3io Directory\n",
    "\n",
    "The **v3io** directory that you see in the file browser of the Jupyter UI displays the contents of the `v3io` data mount for browsing the platform data containers.\n",
    "For information about the predefined data containers and data mounts and how to reference data in these containers, see [Platform Data Containers](getting-started/getting-started-basic.ipynb/#platform-data-containers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"support\"></a>\n",
    "### Support\n",
    "\n",
    "The Iguazio [support team](mailto:support@iguazio.com) will be happy to assist with any questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
