{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iguazio Getting Started Example\n",
    "\n",
    "This notebook contains code examples for performing common tasks to help you get started with the Iguazio Continous Data Platform\n",
    "\n",
    "Follow the tutorial by running the paragraphs in order of appearance.\n",
    "\n",
    "> **Tip:** You can also browse the files and directories that you write to the \"users\" container in this tutorial from the platform dashboard: in the side navigation menu, select **Data**, and then select the **users** container from the table. On the container data page, select the **Browse** tab, and then use the side directory-navigation tree to browse the directories. Selecting a file or directory in the browse table displays its metadata.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load a sample CSV file from S3\n",
    "Use `curl` to download a sample stock data from Iguazio public S3 bucket.<br>\n",
    "This file belongs to deutsche-boerse public dataset.<br>\n",
    "For additional public datasets check out (https://registry.opendata.aws/) <br>\n",
    "<br>\n",
    "Note that each user in the system has its own home directory (similar to linux home) that resides in a default container called users <br>\n",
    "The environment variable V3IO_HOME points to the home directory of the logged in user<br>\n",
    "All the notebooks examples store the data under the \"examples\" directory that resides under the user's home directory <br>\n",
    "Iguaizo's best practice is to use the home directory of the user for keeping personal experiments and data in a private workspace <br>\n",
    "However, to work on other folders and share data with other users you need to specify the exact path using the following convention /v3io/\"data container name\"/\"path\" <br>\n",
    "V3io is the name of the iguazio data source library and it is being used to define iguazio as the storage layer for that read/write operation<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  861k  100  861k    0     0   894k      0 --:--:-- --:--:-- --:--:--  894k\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "mkdir -p /v3io/${V3IO_HOME}/examples\n",
    "\n",
    "# Download a sample stocks file from Iguazio demo bucket in S3\n",
    "curl -L \"iguazio-sample-data.s3.amazonaws.com/2018-03-26_BINS_XETR08.csv\" > /v3io/${V3IO_HOME}/examples/stocks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Convert the sample CSV file to a NoSQL table\n",
    "\n",
    "Read the sample stocks.csv file that you downloaded in Step 1 into a Spark DataFrame, and write the data in NoSQL format to a new stocks_nosql table \n",
    "\n",
    "Note: To use the Iguazio Spark Connector, set the data-source format to \"io.iguaz.v3io.spark.sql.kv\". <br>\n",
    "The V3IO_HOME_URL is an environment varible that points to the Home directory of the user using Spark/Hadoop  format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------------------+------------+--------+----------+----------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "|        ISIN|Mnemonic|        SecurityDesc|SecurityType|Currency|SecurityID|      Date| Time|StartPrice|MaxPrice|MinPrice|EndPrice|TradedVolume|NumberOfTrades|\n",
      "+------------+--------+--------------------+------------+--------+----------+----------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "|CH0038389992|    BBZA|BB BIOTECH NAM.  ...|Common stock|     EUR|   2504244|2018-03-26|08:00|      56.4|    56.4|    56.4|    56.4|         320|             4|\n",
      "|CH0038863350|    NESR|NESTLE NAM.      ...|Common stock|     EUR|   2504245|2018-03-26|08:00|     63.04|   63.06|      63|   63.06|         314|             3|\n",
      "|LU0378438732|    C001|COMSTAGE-DAX UCIT...|         ETF|     EUR|   2504271|2018-03-26|08:00|    113.42|  113.42|  113.42|  113.42|         100|             1|\n",
      "|LU0411075020|    DBPD|XTR.SHORTDAX X2 D...|         ETF|     EUR|   2504272|2018-03-26|08:00|    4.1335|  4.1335|  4.1295|    4.13|      102993|             8|\n",
      "|LU0838782315|    XDDX|   XTR.DAX INCOME 1D|         ETF|     EUR|   2504277|2018-03-26|08:00|    105.14|   105.2|  105.14|   105.2|         239|             3|\n",
      "|DE000A0DJ6J9|     S92|SMA SOLAR TECHNOL.AG|Common stock|     EUR|   2504287|2018-03-26|08:00|     55.65|   55.65|   55.65|   55.65|         543|             3|\n",
      "|DE000A0D6554|    NDX1|      NORDEX SE O.N.|Common stock|     EUR|   2504290|2018-03-26|08:00|     8.182|    8.21|   8.174|    8.21|       10941|             8|\n",
      "|DE000A0F5UE8|    EXXU|IS.DJ CHINA OFFS....|         ETF|     EUR|   2504302|2018-03-26|08:00|     47.52|   47.52|   47.52|   47.52|         420|             1|\n",
      "|DE000A0HN5C6|    DWNI|DEUTSCHE WOHNEN S...|Common stock|     EUR|   2504314|2018-03-26|08:00|      36.2|   36.24|    36.2|   36.24|         580|             5|\n",
      "|DE000A0LD2U1|     AOX|ALSTRIA OFFICE RE...|Common stock|     EUR|   2504379|2018-03-26|08:00|     12.25|   12.25|   12.25|   12.25|        1728|             3|\n",
      "|DE000A0LR936|     ST5|           STEICO SE|Common stock|     EUR|   2504382|2018-03-26|08:00|     22.35|   22.35|   22.35|   22.35|         334|             1|\n",
      "|DE000A0MZ4B0|     DLX|DELIGNIT AG      ...|Common stock|     EUR|   2504390|2018-03-26|08:00|      10.3|    10.3|    10.3|    10.3|         850|             1|\n",
      "|DE000A0Q8NC8|    ETLX|ETFS DAXGL.G.MIN....|         ETF|     EUR|   2504397|2018-03-26|08:00|    17.844|  17.844|  17.838|  17.838|        3085|             5|\n",
      "|DE000A0V9YU8|    4RT3|ETFS COM.SEC.DZ08...|         ETC|     EUR|   2504421|2018-03-26|08:00|    5.8895|  5.8895|  5.8895|  5.8895|           0|             1|\n",
      "|DE000A0WMPJ6|    AIXA|  AIXTRON SE NA O.N.|Common stock|     EUR|   2504428|2018-03-26|08:00|      16.8|    16.8|   16.75|  16.755|        3329|             8|\n",
      "|DE000A0Z2XN6|     RIB|RIB SOFTWARE SE  ...|Common stock|     EUR|   2504436|2018-03-26|08:00|     24.66|   24.66|   24.52|   24.52|       11741|            29|\n",
      "|DE000A0Z2ZZ5|    FNTN|  FREENET AG NA O.N.|Common stock|     EUR|   2504438|2018-03-26|08:00|     24.41|   24.42|   24.41|   24.42|         695|             6|\n",
      "|DE000A1A6V48|     KSC|      KPS AG NA O.N.|Common stock|     EUR|   2504441|2018-03-26|08:00|      9.15|    9.15|    9.15|    9.15|          73|             1|\n",
      "|DE000A1DAHH0|     BNR| BRENNTAG AG NA O.N.|Common stock|     EUR|   2504453|2018-03-26|08:00|     48.14|   48.14|   48.14|   48.14|         185|             2|\n",
      "|DE000A1EWWW0|     ADS|   ADIDAS AG NA O.N.|Common stock|     EUR|   2504471|2018-03-26|08:00|     196.3|  196.35|   196.3|  196.35|         591|            12|\n",
      "+------------+--------+--------------------+------------+--------+----------+----------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Iguazio getting started\").getOrCreate()\n",
    "\n",
    "file_path=os.path.join(os.getenv('V3IO_HOME_URL')+'/examples')\n",
    "\n",
    "# Read the sample stocks.csv file into a Spark DataFrame, and let Spark infer the schema of the CSV file\n",
    "df = spark.read.option(\"header\", \"true\").csv(os.path.join(file_path)+'/stocks.csv')\n",
    "\n",
    "# Show the DataFrame data\n",
    "df.show()\n",
    "\n",
    "# Write the DataFrame data to a stocks_tab table under \"users\" container and define \"ISIN\" column as a key\n",
    "df.write.format(\"io.iguaz.v3io.spark.sql.kv\").mode(\"append\").option(\"key\", \"ISIN\").option(\"allow-overwrite-schema\", \"true\").save(os.path.join(file_path)+'/stocks_tab/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run interactive SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from v3io.users.\"iguazio/examples/stocks_tab\" where tradedvolume > 11000 order by tradedvolume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert the stocks_nosql table to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').parquet(os.path.join(file_path)+'/stocks_prqt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Display the content of the example container directory\n",
    "Use hadoop fs to list the contents of the root directory under “users” container where all the example files are located\n",
    "You should see in this directory the stocks.csv file and the stocks_nosql and stocks_prqt table directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxrwxrwx. 2 50 nogroup      0 Feb 24 08:04 stocks_tab\n",
      "-rw-r--r--. 1 50 nogroup 882055 Feb 24 08:59 stocks.csv\n",
      "drwxr-xr-x. 2 50 nogroup      0 Feb 24 09:19 stocks_prqt2\n",
      "drwxr-xr-x. 2 50 nogroup      0 Feb 24 09:20 stocks_prqt\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt /v3io/${V3IO_HOME}/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "-rw-r--r--   1 50 nogroup     882055 2019-02-24 08:59 v3io://users/iguazio/examples/stocks.csv\n",
      "drwxr-xr-x   - 50 nogroup          0 2019-02-24 09:20 v3io://users/iguazio/examples/stocks_prqt\n",
      "drwxr-xr-x   - 50 nogroup          0 2019-02-24 09:19 v3io://users/iguazio/examples/stocks_prqt2\n",
      "drwxrwxrwx   - 50 nogroup          0 2019-02-24 08:04 v3io://users/iguazio/examples/stocks_tab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/02/24 09:22:32 INFO slf_4j.Slf4jLogger: Slf4jLogger started\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# List the files and directories in the root directory of the \"users\" container using hadoop\n",
    "hadoop fs -ls ${V3IO_HOME_URL}/examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all files under my example directory\n",
    "!rm -rf /v3io/${V3IO_HOME}/examples/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to release compute and memory resources taken by spark we recommend running the following command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
