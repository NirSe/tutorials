{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Spark Streaming, SQL, and ML with iguazio\n",
    "Spark users can access files, tables or streams stored on iguazio data platform through the native spark Dataframe interfaces. <br>\n",
    "iguazio drivers for Spark implement the data-source API and allow `predicate push down` (the queries pass to iguazio database which only return the relevant data), this allow accelerated and high-speed access from Spark to data stored in iguazio DB. for more details read [Spark API documentation]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading a file from AWS S3 into iguazio file system  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  975k  100  975k    0     0  8329k      0 --:--:-- --:--:-- --:--:-- 8338k\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "mkdir -p /v3io/bigdata/examples\n",
    "curl -L \"deutsche-boerse-xetra-pds.s3.amazonaws.com/2018-03-26/2018-03-26_BINS_XETR07.csv\" > /v3io/bigdata/examples/stocks.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiating a Spark session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Iguazio Integration demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "To use the Iguazio Spark connector to read or write NoSQL data in the platform, use the format method to set the DataFrame’s data-source format to the platform’s custom NoSQL data source — \"io.iguaz.v3io.spark.sql.kv\". See the following read and write examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the csv file using Spark DF\n",
    "You can use the custom NoSQL DataFrame inferSchema read option to automatically infer the schema of the read table from its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "|        ISIN|Mnemonic|        SecurityDesc|SecurityType|Currency|SecurityID|               Date| Time|StartPrice|MaxPrice|MinPrice|EndPrice|TradedVolume|NumberOfTrades|\n",
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "|AT0000A0E9W5|    SANT|S+T AG (Z.REG.MK....|Common stock|     EUR|   2504159|2018-03-26 00:00:00|07:00|     20.56|   20.56|   20.56|   20.56|        1115|             5|\n",
      "|DE000A0WMPJ6|    AIXA|  AIXTRON SE NA O.N.|Common stock|     EUR|   2504428|2018-03-26 00:00:00|07:00|    17.035|   17.08|   16.92|   16.98|        2892|            11|\n",
      "|DE000A0Z2XN6|     RIB|RIB SOFTWARE SE  ...|Common stock|     EUR|   2504436|2018-03-26 00:00:00|07:00|     24.02|   24.18|   23.94|   24.12|        5721|            34|\n",
      "|DE000A0Z2ZZ5|    FNTN|  FREENET AG NA O.N.|Common stock|     EUR|   2504438|2018-03-26 00:00:00|07:00|     24.72|   24.72|    24.7|   24.72|         315|             2|\n",
      "|DE000A1EWWW0|     ADS|   ADIDAS AG NA O.N.|Common stock|     EUR|   2504471|2018-03-26 00:00:00|07:00|    196.35|   196.4|   195.6|   195.9|        5616|            27|\n",
      "|DE000A1J5RX9|     O2D|TELEFONICA DTLD H...|Common stock|     EUR|   2504492|2018-03-26 00:00:00|07:00|      3.73|    3.73|    3.73|    3.73|        6400|             5|\n",
      "|DE000A1ML7J1|     VNA|  VONOVIA SE NA O.N.|Common stock|     EUR|   2504501|2018-03-26 00:00:00|07:00|     39.42|   39.49|   39.42|   39.45|        2187|            12|\n",
      "|DE000A1X3W00|    MDG1| MEDIGENE AG NA O.N.|Common stock|     EUR|   2504531|2018-03-26 00:00:00|07:00|     14.44|   14.44|   14.37|    14.4|        1601|             4|\n",
      "|DE000A111338|    AM3D|SLM SOLUTIONS GRP AG|Common stock|     EUR|   2504550|2018-03-26 00:00:00|07:00|     33.35|   33.35|   33.35|   33.35|          40|             1|\n",
      "|DE000A2DAM03|     AAG|           AUMANN AG|Common stock|     EUR|   2504639|2018-03-26 00:00:00|07:00|      55.0|    55.0|    55.0|    55.0|           7|             1|\n",
      "|DE000BASF111|     BAS|     BASF SE NA O.N.|Common stock|     EUR|   2504663|2018-03-26 00:00:00|07:00|     81.48|   81.49|    81.3|   81.39|        5317|            47|\n",
      "|DE000BAY0017|    BAYN|    BAYER AG NA O.N.|Common stock|     EUR|   2504664|2018-03-26 00:00:00|07:00|      90.9|    90.9|   90.77|   90.86|        5323|            34|\n",
      "|DE000CBK1001|     CBK|      COMMERZBANK AG|Common stock|     EUR|   2504665|2018-03-26 00:00:00|07:00|     11.09|   11.09|   11.04|  11.058|       23698|            17|\n",
      "|DE000WAF3001|     WAF|SILTRONIC AG NA O.N.|Common stock|     EUR|   2504859|2018-03-26 00:00:00|07:00|     149.4|   149.4|   149.3|   149.4|         200|             4|\n",
      "|DE000XNG8888|    O1BC|    XING SE  NA O.N.|Common stock|     EUR|   2504862|2018-03-26 00:00:00|07:00|     240.5|   240.5|   240.0|   240.0|          42|             3|\n",
      "|DE0005089031|    UTDI|  UTD.INTERNET AG NA|Common stock|     EUR|   2504878|2018-03-26 00:00:00|07:00|     52.82|   52.82|   52.82|   52.82|          76|             2|\n",
      "|DE0005140008|     DBK|DEUTSCHE BANK AG ...|Common stock|     EUR|   2504888|2018-03-26 00:00:00|07:00|     11.39|   11.39|  11.358|   11.37|       24466|            46|\n",
      "|DE0005158703|     BC8|     BECHTLE AG O.N.|Common stock|     EUR|   2504894|2018-03-26 00:00:00|07:00|      66.4|   66.45|    66.4|    66.4|         280|             4|\n",
      "|DE0005190003|     BMW|BAY.MOTOREN WERKE...|Common stock|     EUR|   2504900|2018-03-26 00:00:00|07:00|     84.82|   84.84|   84.59|    84.7|        3241|            35|\n",
      "|DE0005200000|     BEI|  BEIERSDORF AG O.N.|Common stock|     EUR|   2504906|2018-03-26 00:00:00|07:00|     87.16|   87.16|   87.08|   87.16|         961|            14|\n",
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv('v3io://bigdata/examples/stocks.csv')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the spark DF into a table in Iguazio DB\n",
    "Specify the path to the NoSQL table that is associated with the DataFrame as a fully qualified path of the format v3io://container name/data path —\n",
    "where container name is the name of the table’s parent container, and data path is the path to the data within the specified container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the DB index key using the key option (note the key must be unique)\n",
    "df.write.format(\"io.iguaz.v3io.spark.sql.kv\").mode(\"append\").option(\"key\", \"ISIN\").save(\"v3io://bigdata/examples/stocks_tab\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a table via Spark DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "|        ISIN|Mnemonic|        SecurityDesc|SecurityType|Currency|SecurityID|               Date| Time|StartPrice|MaxPrice|MinPrice|EndPrice|TradedVolume|NumberOfTrades|\n",
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "|FR0011475078|    JPNH|LYX.JAP.(TOPIX)(D...|         ETF|     EUR|   2505326|2018-03-26 00:00:00|07:36|   131.745| 131.745| 131.745| 131.745|         400|             1|\n",
      "|US5951121038|     MTE|MICRON TECHN. INC...|Common stock|     EUR|   2506531|2018-03-26 00:00:00|07:04|      44.5|    44.5|    44.5|    44.5|        1000|             4|\n",
      "|GB0000566504|     BIL|BHP BILLITON     ...|Common stock|     EUR|   2505369|2018-03-26 00:00:00|07:10|     15.96|  15.974|   15.96|  15.974|         110|             2|\n",
      "|DE000A0H08K7|    EXH5|IS.S.E.600 INSUR....|         ETF|     EUR|   2504328|2018-03-26 00:00:00|07:06|     28.02|   28.02|   28.02|   28.02|       16234|             1|\n",
      "|DE000A12B8Z4|     TLG|   TLG IMMOBILIEN AG|Common stock|     EUR|   2504555|2018-03-26 00:00:00|07:03|      22.6|    22.6|    22.6|    22.6|         405|             1|\n",
      "|CA9628791027|     SII|WHEATON PREC. METALS|Common stock|     EUR|   2504200|2018-03-26 00:00:00|07:18|     16.51|   16.51|   16.51|   16.51|           1|             1|\n",
      "|DE000A14KL72|     VSC|              4SC AG|Common stock|     EUR|   2504585|2018-03-26 00:00:00|07:02|      7.25|    7.25|    7.24|    7.24|        1788|             3|\n",
      "|IE00BJ0KDQ92|    XDWD| X(IE)-MSCI WORLD 1C|         ETF|     EUR|   2505424|2018-03-26 00:00:00|07:24|     46.94|   46.94|   46.94|   46.94|          40|             1|\n",
      "|DE000A0X9AA8|    DES2|ETFS DAX DLY2XSH....|         ETF|     EUR|   2504257|2018-03-26 00:00:00|07:15|     5.111|   5.112|    5.11|   5.112|       14500|             7|\n",
      "|DE000A0HGQF5|     MF6|         MAGFORCE AG|Common stock|     EUR|   2504308|2018-03-26 00:00:00|07:03|      5.97|    5.97|     5.9|    5.97|        3021|             4|\n",
      "|CH0244767585|     0UB|UBS GROUP AG     ...|Common stock|     EUR|   2504253|2018-03-26 00:00:00|07:04|    14.185|  14.185|  14.185|  14.185|          86|             1|\n",
      "|DE000TUAG000|    TUI1|      TUI AG NA O.N.|Common stock|     EUR|   2504855|2018-03-26 00:00:00|07:02|     17.28|  17.285|   17.28|   17.28|        1133|             4|\n",
      "|DE000A2E4MK4|    NUVA|NORATIS AG  INH. ...|Common stock|     EUR|   2519875|2018-03-26 00:00:00|07:03|      26.4|    26.4|    26.4|    26.4|          55|             1|\n",
      "|FR0000125007|     GOB|ST GOBAIN        ...|Common stock|     EUR|   2505181|2018-03-26 00:00:00|07:55|     42.93|   42.93|   42.93|   42.93|         100|             1|\n",
      "|DE0007030009|     RHM|      RHEINMETALL AG|Common stock|     EUR|   2505071|2018-03-26 00:00:00|07:02|     111.0|   111.0|   111.0|   111.0|         127|             1|\n",
      "|DE0007165607|     SRT|   SARTORIUS AG O.N.|Common stock|     EUR|   2505078|2018-03-26 00:00:00|07:02|     101.0|   101.0|   100.0|   100.0|          79|             5|\n",
      "|BE0974293251|    1NBA|ANHEUSER-BUSCH INBEV|Common stock|     EUR|   2504195|2018-03-26 00:00:00|07:13|      87.4|    87.4|    87.4|    87.4|          60|             1|\n",
      "|LU1104579369|    E043|COMST.-LEVDAX X2 ...|         ETF|     EUR|   2504278|2018-03-26 00:00:00|07:18|    11.078|  11.078|  11.078|  11.078|        1800|             1|\n",
      "|IE0031442068|    IUSA|   ISHS-S+P 500 DL D|         ETF|     EUR|   2505798|2018-03-26 00:00:00|07:04|    21.098|  21.098|  21.098|  21.098|           0|             1|\n",
      "|IE00B0M62Q58|    IQQW|ISHS-MSCI WORLD DL D|         ETF|     EUR|   2505568|2018-03-26 00:00:00|07:04|      35.3|    35.3|   35.29|    35.3|        1200|             3|\n",
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"io.iguaz.v3io.spark.sql.kv\").load(\"v3io://bigdata/examples/stocks_tab\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"v3io://bigdata/examples/stocks_tab.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Schema-Overwrite Examples\n",
    "The following example creates a table named mytable with AttrA and AttrB attributes of type string and an AttrC attribute of type long, and then overwrites the table schema to change the type of AttrC to double:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (\"a\", \"z\", 123),\n",
    "    (\"b\", \"y\", 456)\n",
    "], [\"AttrA\", \"AttrB\", \"AttrC\"])\n",
    "df.write.format(\"io.iguaz.v3io.spark.sql.kv\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"key\", \"AttrA\") \\\n",
    "    .save(\"v3io://bigdata/examples/mytable/\")\n",
    "    \n",
    "df = spark.createDataFrame([\n",
    "    (\"c\", \"x\", 32.12),\n",
    "    (\"d\", \"v\", 45.2)\n",
    "], [\"AttrA\", \"AttrB\", \"AttrC\"])\n",
    "df.write.format(\"io.iguaz.v3io.spark.sql.kv\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"key\", \"AttrA\") \\\n",
    "    .option(\"allow-overwrite-schema\", \"true\") \\\n",
    "    .save(\"v3io://bigdata/examples/mytable/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a partition table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This examples creates a partitioned “weather” table  The option(\"partition\", \"year, month, day\") write option partitions the table by the year, month, and day item attributes. As demonstrated in the following image, if you browse the container in the dashboard after running the example, you’ll see that the weather directory has year=<value>/month=<value>/day=<value> partition directories that match the written items. If you select any of the nested day partition directories, you can see the written items and their attributes. For example, the first item (with attribute values 2016, 3, 25, 6, 16, 0.00, 55) is saved to a 20163256 file in a weather/year=2016/month=3/day=25 partition directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = \"v3io://bigdata/examples/weather/\"\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (2016,  3, 25, 17, 18, 0.2, 62),\n",
    "    (2016,  7, 24,  7, 19, 0.0, 52),\n",
    "    (2016, 12, 24,  9, 10, 0.1, 47),\n",
    "    (2017,  5,  7, 14, 21, 0.0, 70),\n",
    "    (2017, 11,  1, 10, 15, 0.0, 34),\n",
    "    (2017, 12, 12, 16, 12, 0.0, 47),\n",
    "    (2017, 12, 24, 17, 11, 1.0, 50),\n",
    "    (2018,  1, 18, 17, 10, 2.0, 45),\n",
    "    (2018,  5, 20, 21, 20, 0.0, 59),\n",
    "    (2018, 11,  1, 11, 11, 0.1, 65)\n",
    "], [\"year\", \"month\", \"day\", \"hour\", \"degrees_cel\", \"rain_ml\", \"humidity_per\"])\n",
    "df_with_key = df.withColumn(\n",
    "    \"time\", concat(df[\"year\"], df[\"month\"], df[\"day\"], df[\"hour\"]))\n",
    "df_with_key.write.format(\"io.iguaz.v3io.spark.sql.kv\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"key\", \"time\") \\\n",
    "    .option(\"partition\", \"year, month, day, hour\") \\\n",
    "    .save(table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from partition table\n",
    "Following is the output of the example’s show commands for each read. The filtered results are gathered by scanning only the partition directories that match the filter criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full table read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "|year|month|day|hour|degrees_cel|rain_ml|humidity_per|      time|\n",
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "|2016|   12| 24|   9|         10|    0.1|          47| 201612249|\n",
      "|2016|    3| 25|  17|         18|    0.2|          62| 201632517|\n",
      "|2016|    7| 24|   7|         19|    0.0|          52|  20167247|\n",
      "|2017|   11|  1|  10|         15|    0.0|          34| 201711110|\n",
      "|2017|   12| 12|  16|         12|    0.0|          47|2017121216|\n",
      "|2017|   12| 24|  17|         11|    1.0|          50|2017122417|\n",
      "|2017|    5|  7|  14|         21|    0.0|          70|  20175714|\n",
      "|2018|    1| 18|  17|         10|    2.0|          45| 201811817|\n",
      "|2018|   11|  1|  11|         11|    0.1|          65| 201811111|\n",
      "|2018|    5| 20|  21|         20|    0.0|          59| 201852021|\n",
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readDF = spark.read.format(\"io.iguaz.v3io.spark.sql.kv\").load(table_path)\n",
    "readDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### month < 7 filter — retrieve all data for the first six months of each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "|year|month|day|hour|degrees_cel|rain_ml|humidity_per|      time|\n",
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "|2016|   12| 24|   9|         10|    0.1|          47| 201612249|\n",
      "|2016|    7| 24|   7|         19|    0.0|          52|  20167247|\n",
      "|2017|   11|  1|  10|         15|    0.0|          34| 201711110|\n",
      "|2017|   12| 12|  16|         12|    0.0|          47|2017121216|\n",
      "|2017|   12| 24|  17|         11|    1.0|          50|2017122417|\n",
      "|2018|   11|  1|  11|         11|    0.1|          65| 201811111|\n",
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readDF = spark.read.format(\"io.iguaz.v3io.spark.sql.kv\").load(table_path) \\\n",
    "    .filter(\"month > 6\")\n",
    "readDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### month == 12 AND day == 24 filter — retrieve all hours on Dec 24 each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "|year|month|day|hour|degrees_cel|rain_ml|humidity_per|      time|\n",
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "|2016|   12| 24|   9|         10|    0.1|          47| 201612249|\n",
      "|2017|   12| 24|  17|         11|    1.0|          50|2017122417|\n",
      "+----+-----+---+----+-----------+-------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readDF = spark.read.format(\"io.iguaz.v3io.spark.sql.kv\").load(table_path) \\\n",
    "    .filter(\"month == 12 AND day == 24\")\n",
    "readDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### month > 6 AND hour >= 8 AND hour <= 20 filter — retrieve 08:00–20:00 data for every day in the last six months of each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+-----------+-------+------------+---------+\n",
      "|year|month|day|hour|degrees_cel|rain_ml|humidity_per|     time|\n",
      "+----+-----+---+----+-----------+-------+------------+---------+\n",
      "|2016|    3| 25|  17|         18|    0.2|          62|201632517|\n",
      "|2017|    5|  7|  14|         21|    0.0|          70| 20175714|\n",
      "|2018|    1| 18|  17|         10|    2.0|          45|201811817|\n",
      "+----+-----+---+----+-----------+-------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "readDF = spark.read.format(\"io.iguaz.v3io.spark.sql.kv\").load(table_path) \\\n",
    "    .filter(\"month < 7 AND hour >= 8 AND hour <= 20\")\n",
    "readDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional update\n",
    "This example demonstrates how to conditionally update NoSQL table items by using the condition write option. Each write call in the example is followed by matching read and show calls to read and display the value of the updated item in the target table after the write operation.\n",
    "\n",
    "The first write command writes an item (row) to a “cars” table . The item’s reg_license primary-key (identity-column) attribute is set to 7843321, the mode attribute is set to “Honda”, and the odometer attribute is set to 29321. The overwrite save mode is used to overwrite the table if it already exists and create it otherwise. Reading the item from the table produces this output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+--------+\n",
      "|reg_license|model|odometer|\n",
      "+-----------+-----+--------+\n",
      "|    7843321|Honda|   29321|\n",
      "+-----------+-----+--------+\n",
      "\n",
      "+-----------+-----+--------+\n",
      "|reg_license|model|odometer|\n",
      "+-----------+-----+--------+\n",
      "|    7843321|Honda|   31718|\n",
      "+-----------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writeDF = spark.createDataFrame([(\"7843321\", \"Honda\", 29321)],\n",
    "                                [\"reg_license\", \"model\", \"odometer\"])\n",
    "writeDF.write.format(\"io.iguaz.v3io.spark.sql.kv\") \\\n",
    "    .option(\"key\", \"reg_license\") \\\n",
    "    .mode(\"overwrite\").save(\"v3io://bigdata/examples/cars/\")\n",
    "readDF = spark.read.format(\"io.iguaz.v3io.spark.sql.kv\") \\\n",
    "    .load(\"v3io://bigdata/examples/cars/\")\n",
    "readDF.show()\n",
    "\n",
    "writeDF = spark.createDataFrame([(\"7843321\", \"Honda\", 31718)],\n",
    "                                [\"reg_license\", \"model\", \"odometer\"])\n",
    "writeDF.write.format(\"io.iguaz.v3io.spark.sql.kv\") \\\n",
    "    .option(\"key\", \"reg_license\") \\\n",
    "    .option(\"condition\", \"${odometer} > odometer\") \\\n",
    "    .mode(\"append\").save(\"v3io://bigdata/examples/cars/\")\n",
    "readDF = spark.read.format(\"io.iguaz.v3io.spark.sql.kv\") \\\n",
    "    .load(\"v3io://bigdata/examples/cars/\")\n",
    "readDF.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SQL queries (using Presto)\n",
    "## Reading the stock_tab table using SQL after being written by Spark DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "# run only once (load SQL magic)\n",
    "%load_ext sql\n",
    "%config SqlMagic.autocommit=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>securitydesc</th>\n",
       "        <th>securitytype</th>\n",
       "        <th>time</th>\n",
       "        <th>isin</th>\n",
       "        <th>minprice</th>\n",
       "        <th>date</th>\n",
       "        <th>endprice</th>\n",
       "        <th>numberoftrades</th>\n",
       "        <th>mnemonic</th>\n",
       "        <th>currency</th>\n",
       "        <th>securityid</th>\n",
       "        <th>maxprice</th>\n",
       "        <th>tradedvolume</th>\n",
       "        <th>startprice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>COMMERZBANK AG</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>07:00</td>\n",
       "        <td>DE000CBK1001</td>\n",
       "        <td>11.04</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>11.058</td>\n",
       "        <td>17</td>\n",
       "        <td>CBK</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504665</td>\n",
       "        <td>11.09</td>\n",
       "        <td>23698</td>\n",
       "        <td>11.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>XTR.MSCI BANGL.SWAP 1CDL</td>\n",
       "        <td>ETF</td>\n",
       "        <td>07:05</td>\n",
       "        <td>LU0659579220</td>\n",
       "        <td>0.8917</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>0.8917</td>\n",
       "        <td>1</td>\n",
       "        <td>XBAN</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2506042</td>\n",
       "        <td>0.8917</td>\n",
       "        <td>37000</td>\n",
       "        <td>0.8917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ISHSIV-FALL.A.H.Y.C.BDDLD</td>\n",
       "        <td>ETF</td>\n",
       "        <td>07:17</td>\n",
       "        <td>IE00BYM31M36</td>\n",
       "        <td>4.4031</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>4.4031</td>\n",
       "        <td>1</td>\n",
       "        <td>QDVQ</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505524</td>\n",
       "        <td>4.4031</td>\n",
       "        <td>195000</td>\n",
       "        <td>4.4031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>E.ON SE NA O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>07:02</td>\n",
       "        <td>DE000ENAG999</td>\n",
       "        <td>8.978</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>8.98</td>\n",
       "        <td>37</td>\n",
       "        <td>EOAN</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504666</td>\n",
       "        <td>8.996</td>\n",
       "        <td>20376</td>\n",
       "        <td>8.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>STEINHOFF INT.HLDG.EO-,50</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>07:02</td>\n",
       "        <td>NL0011375019</td>\n",
       "        <td>0.2535</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>0.2555</td>\n",
       "        <td>27</td>\n",
       "        <td>SNH</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2506267</td>\n",
       "        <td>0.2596</td>\n",
       "        <td>166227</td>\n",
       "        <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>DEUTSCHE BANK AG NA O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>07:00</td>\n",
       "        <td>DE0005140008</td>\n",
       "        <td>11.358</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>11.37</td>\n",
       "        <td>46</td>\n",
       "        <td>DBK</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504888</td>\n",
       "        <td>11.39</td>\n",
       "        <td>24466</td>\n",
       "        <td>11.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>COMMERZBANK ETC UNL.</td>\n",
       "        <td>ETC</td>\n",
       "        <td>07:11</td>\n",
       "        <td>DE000ETC0308</td>\n",
       "        <td>0.284</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>0.284</td>\n",
       "        <td>1</td>\n",
       "        <td>X0D2</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2506314</td>\n",
       "        <td>0.284</td>\n",
       "        <td>30000</td>\n",
       "        <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>DK EO STOXX SEL.DIVID.30</td>\n",
       "        <td>ETF</td>\n",
       "        <td>07:11</td>\n",
       "        <td>DE000ETFL078</td>\n",
       "        <td>19.924</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>19.924</td>\n",
       "        <td>2</td>\n",
       "        <td>EL4G</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2506378</td>\n",
       "        <td>19.924</td>\n",
       "        <td>40599</td>\n",
       "        <td>19.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>COMMERZBANK ETC UNL.</td>\n",
       "        <td>ETC</td>\n",
       "        <td>07:31</td>\n",
       "        <td>DE000ETC0290</td>\n",
       "        <td>2.379</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>2.379</td>\n",
       "        <td>1</td>\n",
       "        <td>X0D1</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2506313</td>\n",
       "        <td>2.379</td>\n",
       "        <td>54500</td>\n",
       "        <td>2.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>BEATE UHSE AG</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>07:03</td>\n",
       "        <td>DE0007551400</td>\n",
       "        <td>0.02</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>0.0205</td>\n",
       "        <td>4</td>\n",
       "        <td>USE</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505107</td>\n",
       "        <td>0.0205</td>\n",
       "        <td>245598</td>\n",
       "        <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AMUNDI ETF MSCI EMER.MKTS</td>\n",
       "        <td>ETF</td>\n",
       "        <td>07:04</td>\n",
       "        <td>FR0010959676</td>\n",
       "        <td>4.1296</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>4.1296</td>\n",
       "        <td>2</td>\n",
       "        <td>AMEM</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505311</td>\n",
       "        <td>4.1296</td>\n",
       "        <td>57117</td>\n",
       "        <td>4.1296</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('COMMERZBANK AG', 'Common stock', '07:00', 'DE000CBK1001', 11.04, '2018-03-26 00:00:00.000', 11.058, 17, 'CBK', 'EUR', 2504665, 11.09, 23698, 11.09),\n",
       " ('XTR.MSCI BANGL.SWAP 1CDL', 'ETF', '07:05', 'LU0659579220', 0.8917, '2018-03-26 00:00:00.000', 0.8917, 1, 'XBAN', 'EUR', 2506042, 0.8917, 37000, 0.8917),\n",
       " ('ISHSIV-FALL.A.H.Y.C.BDDLD', 'ETF', '07:17', 'IE00BYM31M36', 4.4031, '2018-03-26 00:00:00.000', 4.4031, 1, 'QDVQ', 'EUR', 2505524, 4.4031, 195000, 4.4031),\n",
       " ('E.ON SE NA O.N.', 'Common stock', '07:02', 'DE000ENAG999', 8.978, '2018-03-26 00:00:00.000', 8.98, 37, 'EOAN', 'EUR', 2504666, 8.996, 20376, 8.995),\n",
       " ('STEINHOFF INT.HLDG.EO-,50', 'Common stock', '07:02', 'NL0011375019', 0.2535, '2018-03-26 00:00:00.000', 0.2555, 27, 'SNH', 'EUR', 2506267, 0.2596, 166227, 0.254),\n",
       " ('DEUTSCHE BANK AG NA O.N.', 'Common stock', '07:00', 'DE0005140008', 11.358, '2018-03-26 00:00:00.000', 11.37, 46, 'DBK', 'EUR', 2504888, 11.39, 24466, 11.39),\n",
       " ('COMMERZBANK ETC UNL.', 'ETC', '07:11', 'DE000ETC0308', 0.284, '2018-03-26 00:00:00.000', 0.284, 1, 'X0D2', 'EUR', 2506314, 0.284, 30000, 0.284),\n",
       " ('DK EO STOXX SEL.DIVID.30', 'ETF', '07:11', 'DE000ETFL078', 19.924, '2018-03-26 00:00:00.000', 19.924, 2, 'EL4G', 'EUR', 2506378, 19.924, 40599, 19.924),\n",
       " ('COMMERZBANK ETC UNL.', 'ETC', '07:31', 'DE000ETC0290', 2.379, '2018-03-26 00:00:00.000', 2.379, 1, 'X0D1', 'EUR', 2506313, 2.379, 54500, 2.379),\n",
       " ('BEATE UHSE AG', 'Common stock', '07:03', 'DE0007551400', 0.02, '2018-03-26 00:00:00.000', 0.0205, 4, 'USE', 'EUR', 2505107, 0.0205, 245598, 0.02),\n",
       " ('AMUNDI ETF MSCI EMER.MKTS', 'ETF', '07:04', 'FR0010959676', 4.1296, '2018-03-26 00:00:00.000', 4.1296, 2, 'AMEM', 'EUR', 2505311, 4.1296, 57117, 4.1296)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select * from v3io.bigdata.\"/examples/stocks_tab\" where tradedvolume > 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Data\n",
    "When you are done - cleaning the directory will be done by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmark the comment\n",
    "# !rm -rf /v3io/bigdata/examples/*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
