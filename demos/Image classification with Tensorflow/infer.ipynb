{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Test Model Serving (nuclio) Function\n",
    "The following notebook demonstrates how to write an inferencing server, test it, and turn it into an auto-scaling nuclio function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize nuclio emulation, environment variables and configuration\n",
    "use `# nuclio: ignore` for sections that dont need to be copied to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting 'IMAGE_WIDTH' environment variable\n",
      "%nuclio: setting 'IMAGE_HEIGHT' environment variable\n",
      "%nuclio: setting 'version' environment variable\n"
     ]
    }
   ],
   "source": [
    "%%nuclio env\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128\n",
    "version = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting 'MODEL_PATH' environment variable\n"
     ]
    }
   ],
   "source": [
    "%nuclio env -c MODEL_PATH=/model/\n",
    "%nuclio env -l MODEL_PATH=./model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "pip install git+https://github.com/fchollet/keras\n",
    "pip install tensorflow \n",
    "pip install numpy\n",
    "pip install requests\n",
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.build.baseImage to 'python:3.6-jessie'\n"
     ]
    }
   ],
   "source": [
    "%%nuclio config \n",
    "spec.build.baseImage = \"python:3.6-jessie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mounting volume path /model as ~/demos/cats_dogs/model\n"
     ]
    }
   ],
   "source": [
    "%nuclio mount /model ~/demos/cats_dogs/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Load Model and setup handeler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import os\n",
    "from os import environ, path\n",
    "from tempfile import mktemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = environ['MODEL_PATH'] + 'cats_dogs.hd5'\n",
    "prediction_map_file = environ['MODEL_PATH'] + 'prediction_classes_map.json'\n",
    "\n",
    "# set image parameters\n",
    "IMAGE_WIDTH = int(environ['IMAGE_WIDTH'])\n",
    "IMAGE_HEIGHT = int(environ['IMAGE_HEIGHT'])\n",
    "\n",
    "# load model\n",
    "def init_context(context): \n",
    "    context.model = load_model(model_file)\n",
    "    with open(prediction_map_file, 'r') as f:\n",
    "        context.prediction_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(context, url, target_path):\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        with open(target_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "    context.logger.info_with('Downloaded file',url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(context, event):\n",
    "    tmp_file = mktemp()\n",
    "    image_url = event.body.decode('utf-8').strip()\n",
    "    download_file(context, image_url, tmp_file)\n",
    "    \n",
    "    img = load_img(tmp_file, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    predicted_probability = context.model.predict_proba(images, batch_size=10)\n",
    "    predicted_class = list(zip(predicted_probability, map(lambda x: '1' if x >= 0.5 else '0', predicted_probability)))\n",
    "    actual_class = [(context.prediction_map[x[1]],x[0][0]) for x in predicted_class]   \n",
    "    os.remove(tmp_file)\n",
    "    return str(actual_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "init_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "# Select sample for the test (both local path for test and the URL from S3)\n",
    "DATA_LOCATION = \"./cats_and_dogs_filtered/\"\n",
    "sample = random.choice(os.listdir(DATA_LOCATION+\"/cats_n_dogs\"))\n",
    "image_local = DATA_LOCATION + \"cats_n_dogs/\"+sample #temp to get a file \n",
    "image_url = 'https://s3.amazonaws.com/iguazio-sample-data/images/catanddog/' + sample \n",
    "\n",
    "# show the image\n",
    "img = load_img(image_local, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "plt.imshow(img)\n",
    "\n",
    "event = nuclio.Event(body=bytes(image_url, 'utf-8'))\n",
    "output = handler(context, event)\n",
    "print(f'output:\\nclass:{output[0][0]},\\tdog-probability:{output[0][1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: ['deploy', '-n', 'cats-dogs', '-p', 'ai', '-c', '/User/demos/cats_dogs/infer.ipynb']\n",
      "%nuclio: [nuclio.deploy] 2019-03-17 23:59:02,689 (info) Building processor image\n",
      "%nuclio: [nuclio.deploy] 2019-03-17 23:59:04,713 (info) Pushing image\n",
      "%nuclio: [nuclio.deploy] 2019-03-17 23:59:04,713 (info) Build complete\n",
      "%nuclio: [nuclio.deploy] 2019-03-17 23:59:09,764 done updating cats-dogs, function address: 18.184.175.114:31731\n",
      "%nuclio: function deployed\n"
     ]
    }
   ],
   "source": [
    "%nuclio deploy -n cats-dogs -p ai -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 0.0)]"
     ]
    }
   ],
   "source": [
    "!curl -X POST -d \"https://s3.amazonaws.com/iguazio-sample-data/images/catanddog/cat.2004.jpg\" 18.184.175.114:31731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
