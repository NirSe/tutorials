{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Platform Use-Case Application Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Overview](#overview)\n",
    "- [Natural Language Processing (NLP)](#nlp-demo)\n",
    "- [Real-Time Location-Based Recommendations](#location-based-recommendations-demo)\n",
    "- [Real-Time User Segmentation](#user-segmentation-demo)\n",
    "- [Smark Stock Trading](#stocks-demo)\n",
    "- [Stream Enrichment](#stream-enrich-demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview\n",
    "\n",
    "The **demos** tutorials directory contains full end-to-end use-case applications (demos) that demonstrate how to use the Iguazio Data Science Platform (\"the platform\") and related tools to address data science requirements for different industries and implementations.\n",
    "\n",
    "> <a id=\"mlrun-demos-note\"></a>**Note:**<br>\n",
    "> You can get additional demos from the **mlrun/demos** GitHub repository by running the following code.<br>\n",
    "> The downloaded files include a **README-MLRUN.md** file that describes the demos.<br>\n",
    "> Note that some of the MLRun demos are still works in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MLRun demos\n",
    "!chmod +x /User/get-demos.sh\n",
    "!/User/get-demos.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nlp-demo\"></a>\n",
    "## Natural Language Processing (NLP)\n",
    "\n",
    "The [**nlp**](nlp/nlp-example.ipynb) demo demonstrates natural language processing (NLP): the application processes natural-language textual data &mdash; including spelling correction and sentiment analysis &mdash; and generates a Nuclio serverless function that translates any given text string to another (configurable) language.\n",
    "\n",
    "- The textual data is collected and processed by using the [TextBlob](https://textblob.readthedocs.io/) Python NLP library. The processing includes spelling correction and sentiment analysis.\n",
    "- A serverless function that translates text to another language, which is configured in an environment variable, is generated by using the [Nuclio](https://nuclio.io/) framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"location-based-recommendations-demo\"></a>\n",
    "## Real-Time Location-Based Recommendations\n",
    "\n",
    "The [**location-based recommendations**](location-based-recommendations/01-generate-stores-and-customers.ipynb) demo demonstrates how to generate real-time product purchase recommendations for users of a credit-card company based on the users' physical location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"user-segmentation-demo\"></a>\n",
    "## Real-Time User Segmentation\n",
    "\n",
    "The [**real-time user segmentation**](slots-stream/real-time-user-segmentation.ipynb) demo demonstrates how to build a stream-event processor on a sliding time window for tagging and untagging users based on programmatic rules of user behavior.\n",
    "The events are processed by using a Nuclio function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stocks-demo\"></a>\n",
    "## Smart Stock Trading\n",
    "\n",
    "The [**stocks**](stocks/01-gen-demo-data.ipynb) demo demonstrates a smart stock-trading application: \n",
    "the application reads stock-exchange data from an internet service into a time-series database (TSDB); uses Twitter to analyze the market sentiment on specific stocks, in real time; and saves the data to a platform NoSQL table that is used for generating reports and analyzing and visualizing the data on a Grafana dashboard.\n",
    "\n",
    "- The stock data is read from Twitter by using the [TwythonStreamer](https://twython.readthedocs.io/en/latest/usage/streaming_api.html) Python wrapper to the Twitter Streaming API, and saved to TSDB and NoSQL tables in the platform.\n",
    "- Sentiment analysis is done by using the [TextBlob](https://textblob.readthedocs.io/) Python library for natural language processing (NLP).\n",
    "- The analyzed data is visualized as graphs on a [Grafana](https://grafana.com/grafana) dashboard, which is created from the Jupyter notebook code.\n",
    "  The data is read from both the TSDB and NoSQL stock tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stream-enrich-demo\"></a>\n",
    "## Stream Enrichment\n",
    "\n",
    "The [**stream-enrich**](stream-enrich/stream-enrich.ipynb) demo demonstrates a typical stream-based data-engineering pipeline, which is required in many real-world scenarios: data is streamed from an event streaming engine; the data is enriched, in real time, using data from a NoSQL table; the enriched data is saved to an output data stream and then consumed from this stream.\n",
    "\n",
    "- Car-owner data is streamed into the platform from a simulated streaming engine by using an event-triggered [Nuclio](https://nuclio.io/) serverless function.\n",
    "- The data is written (ingested) into an input platform stream by using the the platform's [Streaming Web API](https://www.iguazio.com/docs/reference/latest-release/api-reference/web-apis/streaming-web-api/).\n",
    "- The input stream data is enriched with additional data, such as the car's color and vendor, and the enriched data is saved to a NoSQL table by using the platform's [NoSQL Web API](https://www.iguazio.com/docs/reference/latest-release/api-reference/web-apis/nosql-web-api/).\n",
    "- The Nuclio function writes the enriched data to an output platform data stream by using the platform's Streaming Web API.\n",
    "- The enriched data is read (consumed) from the output stream by using the platform's Streaming Web API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
