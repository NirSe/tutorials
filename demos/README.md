# End-to-End Platform Use-Case Application Demos

**In This Document**

- [Overview](#overview)
- [Natural Language Processing (NLP)](#nlp-demo)
- [Stream Enrichment](#stream-enrich-demo)
- [Stock Trading](#stocks-demo)

<a id="overview"></a>
## Overview

The **demos** tutorials directory contains full end-to-end use-case applications that demonstrate how to use the Iguazio Data Science Platform ("the platform") and related tools to address data science requirements for different industries and implementations.

## In order to get additional demos run:
!chmod +x /User/get-demos.sh <br>
!/User/get-demos.sh

<a id="image-classification-demo"></a>
## Natural Language Processing (NLP)

The [**nlp**](nlp/nlp-example.ipynb) demo demonstrates natural language processing (NLP): the application processes natural-language textual data &mdash; including spelling correction and sentiment analysis &mdash; and generates a Nuclio serverless function that translates any given text string to another (configurable) language.

- The textual data is collected and processed by using the [TextBlob](https://textblob.readthedocs.io/) Python NLP library. The processing includes spelling correction and sentiment analysis.
- A serverless function that translates text to another language, which is configured in an environment variable, is generated by using the [Nuclio](https://nuclio.io/) framework.

<a id="stocks-demo"></a>
## Smart Stock Trading

The [**stocks**](stocks/01-gen-demo-data.ipynb) demo demonstrates a smart stock-trading application: 
the application reads stock-exchange data from an internet service into a time-series database (TSDB); uses Twitter to analyze the market sentiment on specific stocks, in real time; and saves the data to a platform NoSQL table that is used for generating reports and analyzing and visualizing the data on a Grafana dashboard.

- The stock data is read from Twitter by using the [TwythonStreamer](https://twython.readthedocs.io/en/latest/usage/streaming_api.html) Python wrapper to the Twitter Streaming API, and saved to TSDB and NoSQL tables in the platform.
- Sentiment analysis is done by using the [TextBlob](https://textblob.readthedocs.io/) Python library for natural language processing (NLP).
- The analyzed data is visualized as graphs on a [Grafana](https://grafana.com/grafana) dashboard, which is created from the Jupyter notebook code.
  The data is read from both the TSDB and NoSQL stock tables.

<a id="stream-enrich-demo"></a>
### Stream Enrichment

The [**stream-enrich**](stream-enrich/stream-enrich.ipynb) demo demonstrates a typical stream-based data-engineering pipeline, which is required in many real-world scenarios: data is streamed from an event streaming engine; the data is enriched, in real time, using data from a NoSQL table; the enriched data is saved to an output data stream and then consumed from this stream.

- Car-owner data is streamed into the platform from a simulated streaming engine by using an event-triggered [Nuclio](https://nuclio.io/) serverless function.
- The data is written (ingested) into an input platform stream by using the the platform's [Streaming Web API](https://www.iguazio.com/docs/reference/latest-release/api-reference/web-apis/streaming-web-api/).
- The input stream data is enriched with additional data, such as the car's color and vendor, and the enriched data is saved to a NoSQL table by using the platform's [NoSQL Web API](https://www.iguazio.com/docs/reference/latest-release/api-reference/web-apis/nosql-web-api/).
- The Nuclio function writes the enriched data to an output platform data stream by using the platform's Streaming Web API.
- The enriched data is read (consumed) from the output stream by using the platform's Streaming Web API.
